{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16421ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61fa319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d64f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0xEDA\n",
    "T.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e1ec74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Shanghai_HMT_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43cf98d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape =  (52584, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>season</th>\n",
       "      <th>PM_Jingan</th>\n",
       "      <th>PM_US Post</th>\n",
       "      <th>PM_Xuhui</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>HUMI</th>\n",
       "      <th>PRES</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>Iprec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>59.48</td>\n",
       "      <td>1026.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>59.48</td>\n",
       "      <td>1025.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>59.21</td>\n",
       "      <td>1025.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>63.94</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>63.94</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>59.21</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>59.48</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>69.43</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>64.90</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  season  PM_Jingan  PM_US Post  PM_Xuhui  DEWP  \\\n",
       "0   1  2010      1    1     0       4        NaN         NaN       NaN  -6.0   \n",
       "1   2  2010      1    1     1       4        NaN         NaN       NaN  -6.0   \n",
       "2   3  2010      1    1     2       4        NaN         NaN       NaN  -7.0   \n",
       "3   4  2010      1    1     3       4        NaN         NaN       NaN  -6.0   \n",
       "4   5  2010      1    1     4       4        NaN         NaN       NaN  -6.0   \n",
       "5   6  2010      1    1     5       4        NaN         NaN       NaN  -7.0   \n",
       "6   7  2010      1    1     6       4        NaN         NaN       NaN  -6.0   \n",
       "7   8  2010      1    1     7       4        NaN         NaN       NaN  -5.0   \n",
       "8   9  2010      1    1     8       4        NaN         NaN       NaN  -3.0   \n",
       "9  10  2010      1    1     9       4        NaN         NaN       NaN  -2.0   \n",
       "\n",
       "    HUMI    PRES  TEMP cbwd   Iws  precipitation  Iprec  \n",
       "0  59.48  1026.1   1.0   cv   1.0            0.0    0.0  \n",
       "1  59.48  1025.1   1.0   SE   2.0            0.0    0.0  \n",
       "2  59.21  1025.1   0.0   SE   4.0            0.0    0.0  \n",
       "3  63.94  1024.0   0.0   SE   5.0            0.0    0.0  \n",
       "4  63.94  1023.0   0.0   SE   8.0            0.0    0.0  \n",
       "5  59.21  1023.0   0.0   SE  11.0            0.0    0.0  \n",
       "6  59.48  1023.0   1.0   SE  14.0            0.0    0.0  \n",
       "7  64.18  1023.0   1.0   SE  17.0            0.0    0.0  \n",
       "8  69.43  1023.0   2.0   SE  20.0            0.0    0.0  \n",
       "9  64.90  1023.0   4.0   SE  23.0            0.0    0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"data.shape = \", data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8077ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PM_Jingan','PM_US Post','PM_Xuhui'],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b27ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data[['DEWP','HUMI','TEMP','Iws','precipitation']]\n",
    "#нормировка\n",
    "data_num = ((data_num - data_num.mean())/data_num.std()).dropna(axis=1)\n",
    "data_num = np.array(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8a8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "cbwd = enc.fit_transform(data[['cbwd']]).toarray()\n",
    "hour = enc.fit_transform(data[['hour']]).toarray()\n",
    "month = enc.fit_transform(data[['month']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2679d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([data_num,cbwd,hour,month])\n",
    "median = np.median(np.array(data['PRES']))\n",
    "Y = (np.array(data['PRES'])>=median).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d9d9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X,Y,test_percent=0.2):\n",
    "    test_size = int(test_percent*len(Y))\n",
    "    indices = np.random.permutation(np.arange(len(Y)))\n",
    "    train_indices = indices[test_size:]\n",
    "    test_indices = indices[:test_size]\n",
    "    train_x = X[train_indices]\n",
    "    train_y = Y[train_indices]\n",
    "    test_x = X[test_indices]\n",
    "    test_y = Y[test_indices]\n",
    "    return train_x,test_x,train_y,test_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b26aa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,n_features,reg='none',lr=1e-2,lamb=0.01,n_epochs=100):\n",
    "        self.n_features = n_features\n",
    "        lo = -0.01; hi = 0.01\n",
    "        w = T.rand((n_features), dtype=T.float32, requires_grad=True).to(device)\n",
    "        w = (hi - lo) * w + lo\n",
    "        w.grad = T.zeros(n_features)\n",
    "        w.retain_grad()\n",
    "        self.w = w\n",
    "        b = T.zeros((1), dtype=T.float32, requires_grad=True).to(device)\n",
    "        b.grad = T.zeros(1)\n",
    "        b.retain_grad()\n",
    "        self.b = b\n",
    "        self.reg = reg\n",
    "        self.lr = lr\n",
    "        self.lamda = lamb\n",
    "        self.n_epochs = 100\n",
    "    def fit(self,X,y):\n",
    "        indices = np.arange(len(y))\n",
    "        min_delta = 2e-5\n",
    "        tol_counter = 0\n",
    "        max_tol = 3\n",
    "        prev_loss = T.tensor(float('inf'))\n",
    "        loss = T.tensor(0, dtype=T.float32, requires_grad=True).to(device)\n",
    "        loss.grad = T.tensor(0,dtype=T.float32)\n",
    "        loss.retain_grad()\n",
    "        #print(loss.size())\n",
    "        for epoch in range(0, self.n_epochs):\n",
    "            np.random.shuffle(indices)\n",
    "            batches = self.create_batches(indices)\n",
    "            tot_loss = 0\n",
    "            for batch in batches:\n",
    "                x = train_x[batch]\n",
    "                target = train_y[batch]\n",
    "                oupt = self.forward(x)\n",
    "                loss = (oupt - target).pow(2).mean()\n",
    "                if self.reg=='l2':\n",
    "                    loss+= self.lamda*T.norm(self.w, p=2) # l2 reg\n",
    "                elif self.reg=='l1':\n",
    "                    loss+= self.lamda*T.norm(self.w, p=1) # l1 reg\n",
    "                tot_loss+=loss\n",
    "                loss.backward(retain_graph=True)  # compute gradients\n",
    "                self.w.data += -1 * self.lr * self.w.grad.data\n",
    "                self.b.data += -1 * self.lr * self.b.grad.data\n",
    "                self.w.grad = T.zeros(self.n_features)\n",
    "                self.b.grad = T.zeros(1)\n",
    "                loss.grad = T.tensor(0,dtype=T.float32)\n",
    "            mean_loss = (tot_loss / len(batches)).item()\n",
    "            if prev_loss - mean_loss < min_delta:\n",
    "                tol_counter+=1\n",
    "            else:\n",
    "                tol_counter=0\n",
    "            if tol_counter > max_tol:\n",
    "                break\n",
    "            prev_loss = mean_loss\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch = %4d \" % epoch, end=\"\")\n",
    "                print(\"   loss = %6.4f\" % (mean_loss))\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z = x@self.w\n",
    "        z += self.b\n",
    "        p = 1 / (1 + T.exp(-z))\n",
    "        return p\n",
    "    \n",
    "    def create_batches(self,X,batch_size=128):\n",
    "        batches = []\n",
    "        for i in range(0,len(X)//batch_size):\n",
    "            batches.append(X[i*batch_size:(i+1)*batch_size])\n",
    "        if len(X)%batch_size>0:\n",
    "            batches.append(X[len(X)//batch_size*batch_size:])\n",
    "        return batches        \n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5).type(T.uint8) \n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        batches = self.create_batches(X)\n",
    "        preds = []\n",
    "        for b in batches:\n",
    "            preds.append(self.forward(b))\n",
    "        return T.cat(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c598ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = split(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e8ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Programms\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SL_LogReg\n",
    "sklearn_logreg = SL_LogReg()\n",
    "sklearn_logreg.fit(train_x,train_y)\n",
    "print('Accuracy: %.4f' %(np.sum(np.equal(sklearn_logreg.predict(test_x),test_y))/len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d5761c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Превратим в тензоры:\n",
      "[[ 1.42382658  0.83140845  1.157129   ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.08645215  0.72921794 -0.43931429 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.41697409  0.48249277  0.19926303 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.2156036   1.05837302 -0.22645519 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.22245608  1.41519294  0.73141079 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.42382658  0.56548727  1.26355855 ...  0.          0.\n",
      "   0.        ]]\n",
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Превратим в тензоры:\")\n",
    "print(train_x)\n",
    "print(train_y)\n",
    "\n",
    "train_x = T.tensor(train_x, dtype=T.float32).to(device)\n",
    "train_y = T.tensor(train_y, dtype=T.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2207d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =    0    loss = 0.1848\n",
      "epoch =   10    loss = 0.1041\n",
      "epoch =   20    loss = 0.0997\n",
      "epoch =   30    loss = 0.0978\n",
      "epoch =   40    loss = 0.0968\n",
      "epoch =   50    loss = 0.0962\n",
      "epoch =   60    loss = 0.0958\n",
      "epoch =   70    loss = 0.0957\n",
      "epoch =   80    loss = 0.0956\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_features=train_x.shape[1],reg='l2')\n",
    "logreg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368e4d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_x = T.tensor(test_x, dtype=T.float32).to(device)\n",
    "test_y = T.tensor(test_y, dtype=T.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19191fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9115\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.4f'%(sum(logreg.predict(test_x)==test_y)/len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a0a9be80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
